{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3c7c8-6d00-4374-b014-550ee9527189",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21448,
     "status": "ok",
     "timestamp": 1718984311249,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "83f3c7c8-6d00-4374-b014-550ee9527189",
    "outputId": "85bc7d9b-7aed-489b-d87b-888a9dd9beaf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchaudio\n",
    "from os import path, walk\n",
    "import torch.nn as nn\n",
    "from IPython.display import Audio, display\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WKpmPFVru5d-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25785,
     "status": "ok",
     "timestamp": 1718984340488,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "WKpmPFVru5d-",
    "outputId": "cae14503-14bb-45bf-eb15-30daeb9e0d17"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FeLKmvPj0tBJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60737,
     "status": "ok",
     "timestamp": 1718984401222,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "FeLKmvPj0tBJ",
    "outputId": "3eeff123-1917-4b25-e681-f90a57f1c312"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/My Drive/all_samples_500ms.zip\" -d \"/content\"\n",
    "!unzip \"/content/drive/My Drive/BRIRs_downsampled.zip\" -d \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd3cc2-4097-44b9-8086-2c8d67ebfd63",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1718984401222,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "d0cd3cc2-4097-44b9-8086-2c8d67ebfd63"
   },
   "outputs": [],
   "source": [
    "def data_loader(random_sampling_file):\n",
    "    data = list()\n",
    "    f = open(random_sampling_file, \"r\")\n",
    "    for line in f:\n",
    "        file, brir_name = line.split(\" \")\n",
    "        data.append((brir_name.removesuffix(\"\\n\"), file))\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8efb0-1942-44e4-8b1d-3f3ff36b210b",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1718984401222,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "e5c8efb0-1942-44e4-8b1d-3f3ff36b210b"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, n_observations, n_angles):\n",
    "        super(RNN, self).__init__()\n",
    "        self.n_hidden = 1000\n",
    "        self.gru1 = nn.GRU(n_observations, 256, 1, batch_first=True, bidirectional=False)\n",
    "        self.gru2 = nn.GRU(256, 128, 1, batch_first=True, bidirectional=False)\n",
    "        self.gru3 = nn.GRU(128, 64, 1, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(64*2, n_angles)\n",
    "        self.dropout20 = nn.Dropout(p=0.2)\n",
    "        self.dropout50 = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru1(x)\n",
    "        x = self.dropout20(x)\n",
    "        x, _ = self.gru2(x)\n",
    "        x = self.dropout20(x)\n",
    "        x, _ = self.gru3(x)\n",
    "        x = self.dropout50(x)\n",
    "        x = torch.cat((x[:,0,:],x[:,1,:]), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738afae1-1e3a-45c0-9740-128af30e376d",
   "metadata": {
    "executionInfo": {
     "elapsed": 3425,
     "status": "ok",
     "timestamp": 1718984404645,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "738afae1-1e3a-45c0-9740-128af30e376d"
   },
   "outputs": [],
   "source": [
    "data = data_loader(\"/content/drive/MyDrive/random_sampling_file_brir.txt\")\n",
    "train_data = data[:320000]\n",
    "val_data = data[320000:384000]\n",
    "test_data = data[384000:]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a769cd9-5ada-485a-b528-24f57e2ffc49",
   "metadata": {
    "executionInfo": {
     "elapsed": 494,
     "status": "ok",
     "timestamp": 1718984405138,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "1a769cd9-5ada-485a-b528-24f57e2ffc49"
   },
   "outputs": [],
   "source": [
    "fs = 8000\n",
    "sample_length_secs = 0.5\n",
    "n_observations = int(fs*sample_length_secs)\n",
    "n_angles = 13*5\n",
    "rnn = RNN(n_observations, n_angles).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3d28d-b727-48c0-a9db-26efd82cc715",
   "metadata": {
    "executionInfo": {
     "elapsed": 2188,
     "status": "ok",
     "timestamp": 1718984407325,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "62f3d28d-b727-48c0-a9db-26efd82cc715"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(rnn.parameters(), lr=0.001)\n",
    "az_angles = [\"270\", \"285\", \"300\", \"315\", \"330\", \"345\", \"000\", \"015\", \"030\", \"045\", \"060\", \"075\", \"090\"]\n",
    "el_angles = [\"-45\", \"-20\", \"000\", \"020\", \"045\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MTBjgIfGdWhE",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1718984407325,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "MTBjgIfGdWhE"
   },
   "outputs": [],
   "source": [
    "def convolve_sound(brir, sample):\n",
    "    \"\"\"\n",
    "    Convolves the BRIR with the window, and cuts result at the size of the window length.\n",
    "    window: the window of the sample that should be convolved.\n",
    "\n",
    "    \"\"\"\n",
    "    return torchaudio.functional.convolve(sample.repeat([2,1]).to(device), brir.to(device))[:,:sample.shape[1]]\n",
    "\n",
    "def get_label(brir_name):\n",
    "    az_angles = [\"270\", \"285\", \"300\", \"315\", \"330\", \"345\", \"000\", \"015\", \"030\", \"045\", \"060\", \"075\", \"090\"]\n",
    "    el_angles = [\"-45\", \"-20\", \"000\", \"020\", \"045\"]\n",
    "    az = brir_name.split(\"_\")[12]\n",
    "    el = brir_name.split(\"_\")[14]\n",
    "    return az_angles.index(az)*len(el_angles) + el_angles.index(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba0c4e-ac3d-42af-b3d5-c2c214683ea0",
   "metadata": {},
   "source": [
    "## Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33318ba9-ab3b-42c6-84b4-f02a05b10d28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33318ba9-ab3b-42c6-84b4-f02a05b10d28",
    "outputId": "62b43337-57e6-466c-d9ff-7072c1c117c6"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "writer = SummaryWriter()\n",
    "total_test_loss = 100000\n",
    "training_losses = list()\n",
    "test_losses = list()\n",
    "test_accuracies = list()\n",
    "\n",
    "for epoch in range(50):  # maximum amount of iterations\n",
    "    rnn.train()\n",
    "    training_loss = 0.0\n",
    "    for idx in tqdm(range(0, len(train_data), batch_size)):\n",
    "        batch = train_data[idx:idx+batch_size]\n",
    "        spatial_audios = torch.zeros(batch_size, 2, n_observations, dtype=torch.float32)\n",
    "        labels = torch.zeros(batch_size, dtype=torch.long)\n",
    "\n",
    "        for j, sample in enumerate(batch):\n",
    "            brir_name, filename = sample                  # Split sample into label and filename\n",
    "            brir, _ = torchaudio.load(\"/content/BRIRs_downsampled/\"+brir_name, format=\"wav\")\n",
    "            audio, _ = torchaudio.load(\"/content/all_samples_500ms/\"+filename, format='flac')  # Open audio sample\n",
    "            audio = audio[:,::2].to(device)\n",
    "            spatial_audio = convolve_sound(brir[:,::2], audio).to(device)  # Convolve HRTF and audio sample\n",
    "            spatial_audios[j] = spatial_audio#.flatten()\n",
    "            labels[j] = get_label(brir_name)\n",
    "\n",
    "        spatial_audios = spatial_audios.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = rnn(spatial_audios)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1)\n",
    "        training_loss += loss.item()\n",
    "\n",
    "    total_training_loss = training_loss/(len(train_data)//batch_size)\n",
    "    print(\"Epoch {}:\\n\\ttraining loss: {:.3f}\".format(epoch, total_training_loss))\n",
    "    training_losses.append(total_training_loss)\n",
    "    writer.add_scalar('Loss/train', total_training_loss, epoch)\n",
    "\n",
    "    rnn.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    true_labels = torch.zeros(64000)\n",
    "    predicted_labels = torch.zeros(64000)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        for i, sample in tqdm(enumerate(val_data)):\n",
    "            brir_name, filename = sample                  # Split sample into label and filename\n",
    "            brir, _ = torchaudio.load(\"BRIRs_downsampled/\"+brir_name, format=\"wav\")\n",
    "            audio, _ = torchaudio.load(\"all_samples_500ms/\"+filename, format='flac')  # Open audio sample\n",
    "            audio = audio[:,::2].to(device)\n",
    "            spatial_audio = convolve_sound(brir[:,::2], audio).to(device)  # Convolve HRTF and audio sample\n",
    "            # print(spatial_audio.shape)\n",
    "            output = rnn(spatial_audio.unsqueeze(0))\n",
    "            label = get_label(brir_name)\n",
    "            loss = criterion(output, torch.tensor([label], device=device))\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            # print(predicted.shape)\n",
    "            total += 1\n",
    "            correct += int(int(predicted) == label)\n",
    "            true_labels[i] = label\n",
    "            predicted_labels[i] = predicted\n",
    "\n",
    "    test_accuracy = 100 * correct/total\n",
    "    print(\"\\ttest accuracy: {:,.2f}\".format(test_accuracy))\n",
    "    writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    new_total_test_loss = test_loss/len(val_data)\n",
    "    print(\"\\ttest loss: {:,.3f}\\n\".format(new_total_test_loss))\n",
    "    if new_total_test_loss > total_test_loss:\n",
    "        test_losses.append(new_total_test_loss)\n",
    "        break\n",
    "    else:\n",
    "        torch.save(rnn.state_dict(), '/content/drive/My Drive/BRIR_weights.pth')\n",
    "    writer.add_scalar('Loss/test', new_total_test_loss, epoch)\n",
    "    test_losses.append(new_total_test_loss)\n",
    "    total_test_loss = new_total_test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pRfVtzNepv5u",
   "metadata": {
    "id": "pRfVtzNepv5u"
   },
   "source": [
    "## Test once more on the best variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mN_7LJH4-S9K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2153,
     "status": "ok",
     "timestamp": 1718984409477,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "mN_7LJH4-S9K",
    "outputId": "f9b757f0-5bb1-4e91-c5a2-8cc893f8be81"
   },
   "outputs": [],
   "source": [
    "rnn.load_state_dict(torch.load('/content/drive/My Drive/BRIR_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e32a2-7768-4a5d-b8ad-b2d2bd285484",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1633291,
     "status": "ok",
     "timestamp": 1718986042766,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "188e32a2-7768-4a5d-b8ad-b2d2bd285484",
    "outputId": "f791632a-8166-4f98-ae76-21ac203412f0"
   },
   "outputs": [],
   "source": [
    "rnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "true_labels = torch.zeros(624000)\n",
    "true_az = torch.zeros(624000)\n",
    "true_el = torch.zeros(624000)\n",
    "predicted_labels = torch.zeros(624000)\n",
    "predicted_az = torch.zeros(624000)\n",
    "predicted_el = torch.zeros(624000)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, sample in tqdm(enumerate(test_data)):\n",
    "        brir_name, filename = sample                  # Split sample into label and filename\n",
    "        brir, _ = torchaudio.load(\"BRIRs_16000Hz/\"+brir_name, format=\"wav\")\n",
    "        audio, _ = torchaudio.load(\"samples_500ms/\"+filename, format='flac')  # Open audio sample\n",
    "        audio = audio[:,::2].to(device)\n",
    "        spatial_audio = convolve_sound(brir[:,::2], audio).to(device)  # Convolve HRTF and audio sample\n",
    "        # print(spatial_audio.shape)\n",
    "        output = rnn(spatial_audio.unsqueeze(0))\n",
    "        label = get_label(brir_name)\n",
    "        az = brir_name.split(\"_\")[12]\n",
    "        el = brir_name.split(\"_\")[14]\n",
    "        az_label = az_angles.index(az)\n",
    "        el_label = el_angles.index(el)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        # print(predicted.shape)\n",
    "        total += 1\n",
    "        correct += int(int(predicted) == label)\n",
    "        true_labels[i] = label\n",
    "        predicted_labels[i] = predicted\n",
    "        true_az[i] = az_label\n",
    "        predicted_az[i] = predicted // len(el_angles)\n",
    "        true_el[i] = el_label\n",
    "        predicted_el[i] = predicted % len(el_angles)\n",
    "\n",
    "test_accuracy = 100* correct/total\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLfSg5KTp7ul",
   "metadata": {
    "id": "iLfSg5KTp7ul"
   },
   "source": [
    "## Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa804ef1-43df-45e5-83b5-1de24de63dc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 38020,
     "status": "ok",
     "timestamp": 1718987017900,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "aa804ef1-43df-45e5-83b5-1de24de63dc9",
    "outputId": "7e96f225-b4e6-448b-90d2-1bad7bfcaa2e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "cm = 100 * cm/cm.sum(axis=1)\n",
    "fig, ax = plt.subplots(figsize=(50,50))\n",
    "labels = [\"(\" + az + \",\\n\" + el + \")\" for el in el_angles for az in az_angles]\n",
    "matrix = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "matrix.plot(ax=ax)\n",
    "plt.title(\"Confusion matrix for reverberant data\")\n",
    "plt.savefig(\"azelbrir.svg\", format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LC2mjZjjYjeF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "executionInfo": {
     "elapsed": 993,
     "status": "ok",
     "timestamp": 1718987018889,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "LC2mjZjjYjeF",
    "outputId": "2bb55235-7a3a-48dd-a32f-07ffb6ec6dab"
   },
   "outputs": [],
   "source": [
    "cmaz = confusion_matrix(true_az, predicted_az)\n",
    "cmaz = 100 * cmaz/cmaz.sum(axis=1)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "matrix = ConfusionMatrixDisplay(cmaz, display_labels=az_angles)\n",
    "matrix.plot(ax=ax)\n",
    "plt.title(\"Confusion matrix for reverberant data for azimuth angles combined\")\n",
    "plt.show()\n",
    "plt.savefig(\"azbrir.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9XZ7Q_1YYn6v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718987018889,
     "user": {
      "displayName": "Wessel Ledder",
      "userId": "03089760460695138149"
     },
     "user_tz": -120
    },
    "id": "9XZ7Q_1YYn6v",
    "outputId": "55e4361b-57f8-42df-daa9-bf1741c000f4"
   },
   "outputs": [],
   "source": [
    "cmel = confusion_matrix(true_el, predicted_el)\n",
    "cmel = 100 * cmel/cmel.sum(axis=1)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "matrix = ConfusionMatrixDisplay(cmel, display_labels=el_angles)\n",
    "matrix.plot(ax=ax)\n",
    "plt.title(\"Confusion matrix for reverberant data for\\nelevation angles combined\")\n",
    "plt.show()\n",
    "plt.savefig(\"elbrir.svg\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
